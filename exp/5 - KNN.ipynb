{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import scipy as sc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "# data directory\n",
    "DATA_DIR = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {'A': {'train': os.path.join(DATA_DIR, 'A_hhold_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'A_hhold_test.csv')}, \n",
    "              \n",
    "              'B': {'train': os.path.join(DATA_DIR, 'B_hhold_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'B_hhold_test.csv')}, \n",
    "              \n",
    "              'C': {'train': os.path.join(DATA_DIR, 'C_hhold_train.csv'), \n",
    "                    'test':  os.path.join(DATA_DIR, 'C_hhold_test.csv')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "a_train = pd.read_csv(data_paths['A']['train'], index_col='id')\n",
    "b_train = pd.read_csv(data_paths['B']['train'], index_col='id')\n",
    "c_train = pd.read_csv(data_paths['C']['train'], index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "def standardize(df, numeric_only=True):\n",
    "    numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    # subtracy mean and divide by std\n",
    "    df[numeric.columns] = (numeric - numeric.mean()) / numeric.std()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def pre_process_data(df, enforce_cols=None):\n",
    "    print(\"Input shape:\\t{}\".format(df.shape))\n",
    "        \n",
    "\n",
    "    df = standardize(df)\n",
    "    print(\"After standardization {}\".format(df.shape))\n",
    "        \n",
    "    # create dummy variables for categoricals\n",
    "    df = pd.get_dummies(df)\n",
    "    print(\"After converting categoricals:\\t{}\".format(df.shape))\n",
    "    \n",
    "\n",
    "    # match test set and training set columns\n",
    "    if enforce_cols is not None:\n",
    "        to_drop = np.setdiff1d(df.columns, enforce_cols)\n",
    "        to_add = np.setdiff1d(enforce_cols, df.columns)\n",
    "\n",
    "        df.drop(to_drop, axis=1, inplace=True)\n",
    "        df = df.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country A\n",
      "Input shape:\t(1855, 344)\n",
      "After standardization (1855, 344)\n",
      "After converting categoricals:\t(1855, 849)\n",
      "Shapes: aX_train (1855, 849) - ay_train (1855,)\n",
      "\n",
      "Country B\n",
      "Input shape:\t(3255, 441)\n",
      "After standardization (3255, 441)\n",
      "After converting categoricals:\t(3255, 1432)\n",
      "Shapes: bX_train (3255, 1432) - by_train (3255,)\n",
      "\n",
      "Country C\n",
      "Input shape:\t(6469, 163)\n",
      "After standardization (6469, 163)\n",
      "After converting categoricals:\t(6469, 795)\n",
      "Shapes: cX_train (6469, 795) - cy_train (6469,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Country A\")\n",
    "aX_train = pre_process_data(a_train.drop('poor', axis=1))\n",
    "a_train.fillna(False, inplace=True)\n",
    "ay_train = np.ravel(a_train.poor.astype(int))\n",
    "print(\"Shapes: aX_train {} - ay_train {}\".format(aX_train.shape, ay_train.shape))\n",
    "\n",
    "print(\"\\nCountry B\")\n",
    "bX_train = pre_process_data(b_train.drop('poor', axis=1))\n",
    "b_train.fillna(False, inplace=True)\n",
    "by_train = np.ravel(b_train.poor.astype(int))\n",
    "print(\"Shapes: bX_train {} - by_train {}\".format(bX_train.shape, by_train.shape))\n",
    "\n",
    "print(\"\\nCountry C\")\n",
    "cX_train = pre_process_data(c_train.drop('poor', axis=1))\n",
    "cy_train = np.ravel(c_train.poor.astype(int))\n",
    "print(\"Shapes: cX_train {} - cy_train {}\".format(cX_train.shape, cy_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(x, y):\n",
    "    return train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "def train_model(X, y, params=None):\n",
    "    if params is None:\n",
    "        params = {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
    "    neigh = KNN(**params)\n",
    "    neigh.fit(X, y) \n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, ay_train, ay_test = prepare_data(aX_train, ay_train)\n",
    "b_train, b_test, by_train, by_test = prepare_data(bX_train, by_train)\n",
    "c_train, c_test, cy_train, cy_test = prepare_data(cX_train, cy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss\n",
    "# -log P(yt|yp) = -(yt log(yp) + (1 - yt) log(1 - yp))\n",
    "def log_loss(yt, yp):\n",
    "    # yt: groundtruth\n",
    "    # yp: predicted\n",
    "    ground = np.array(yt)\n",
    "    pred = yp.astype(float)\n",
    "    eps_pred = np.maximum(np.minimum(pred, 1. - 1e-15), 1e-15)\n",
    "    loss = -(ground * np.log(eps_pred) + (1 - ground) * np.log(1 - eps_pred))\n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to find the optimal hyperparameters\n",
    "def tune_params(X, y, X_test, y_test):\n",
    "    params = {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 30, 'p': 2}\n",
    "    current_loss = 10000\n",
    "    best_hyperparams = {}\n",
    "    for n_neighbors in range(5, 10):\n",
    "        for weight in ['uniform']:#, 'distance']:\n",
    "            for algo in ['auto']:#'kd_tree', 'ball_tree', 'brute']:\n",
    "                for leaf_size in [20, 30]:#[5, 10, 20, 30]:\n",
    "                    for p in [1, 2]:\n",
    "                        params['n_neighbors'] = n_neighbors\n",
    "                        params['weights'] = weight\n",
    "                        params['algorithm'] = algo\n",
    "                        params['leaf_size'] = leaf_size\n",
    "                        params['p'] = p\n",
    "\n",
    "                        model = train_model(X, y, params=params)\n",
    "\n",
    "                        pred = model.predict(X_test)\n",
    "                        loss = log_loss(pred, y_test)\n",
    "\n",
    "                        if loss < current_loss:\n",
    "                            current_loss = loss\n",
    "                            best_hyperparams = params\n",
    "\n",
    "    return best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tuning parameters for Country A\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "print(\"\\n\\nTuning parameters for Country A\")\n",
    "a_params = tune_params(a_train, ay_train, a_test, ay_test)\n",
    "#print(\"\\n\\nTuning parameters for Country B\")\n",
    "#b_params, b_num_rounds = tune_params(b_dtrain, b_dtest, by_test)\n",
    "#print(\"\\n\\nTuning parameters for Country C\")\n",
    "#c_params, c_num_rounds = tune_params(c_dtrain, c_dtest, cy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A params: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30, 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"A params: {}\".format(a_params))\n",
    "#print(\"B params: {}\".format(b_params))\n",
    "#print(\"C params: {}\".format(c_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss A Test: 10.14752621085519 - Train: 8.844170231281922\n"
     ]
    }
   ],
   "source": [
    "model_a = train_model(a_train, ay_train, params=a_params)\n",
    "\n",
    "a_pred = model_a.predict(a_test)\n",
    "a_pred_train = model_a.predict(a_train)\n",
    "\n",
    "test_loss_a = log_loss(a_pred, ay_test)\n",
    "train_loss_a = log_loss(a_pred_train, ay_train)\n",
    "\n",
    "print(\"Loss A Test: {} - Train: {}\".format(test_loss_a, train_loss_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
